# =============================================================================
# Training code: mjlab
# Task: Mjlab-Tracking-Flat-Unitree-G1-No-State-Estimation
# =============================================================================

# lowlevel controller
llc_config_file: src/unitree_lowlevel/config/g1.yaml

# [SOURCE] src/mjlab/tasks/tracking/tracking_env_cfg.py: sim.dt=0.005, decimation=4 → policy_dt=0.02
ll_dt: 0.005

# mjlab
policy:
  backend: ort
  model_path: src/legged_rl_deploy/policies/g1/mimic/LAFAN1_Retargeting/dance1_subject1/policy.onnx
  # [SOURCE] ONNX: input shape=[1,154], output shape=[1,29]
  input_dim: 154
  output_dim: 29
  policy_dt: 0.02

  # ---------------------------------------------------------------------------
  # joint_ids_map: maps training-internal index → URDF/hardware index
  # deploy reads: state.joint_pos()[ joint_ids_map[i] ] to fill training slot i
  # [SOURCE] Computed from ONNX metadata joint_names vs URDF joint ordering
  # ---------------------------------------------------------------------------
  joint_ids_map: [    
    0, 1, 2, 3, 4, 5,
    6, 7, 8, 9, 10, 11,
    12, 13, 14,
    15, 16, 17, 18, 19, 20, 21,
    22, 23, 24, 25, 26, 27, 28]

  # [SOURCE] ONNX metadata: joint_stiffness (training order)
  stiffness: [
    40.17923863450712, 99.09842777666111, 40.17923863450712, 99.09842777666111, 28.50124619574858, 28.50124619574858,
    40.17923863450712, 99.09842777666111, 40.17923863450712, 99.09842777666111, 28.50124619574858, 28.50124619574858,
    40.17923863450712, 28.50124619574858, 28.50124619574858,
    14.25062309787429, 14.25062309787429, 14.25062309787429, 14.25062309787429, 14.25062309787429, 16.77832748089279, 16.77832748089279,
    14.25062309787429, 14.25062309787429, 14.25062309787429, 14.25062309787429, 14.25062309787429, 16.77832748089279, 16.77832748089279
  ]
  # [SOURCE] ONNX metadata: joint_damping (training order)
  damping: [
    2.557889775413375, 6.308801853496639, 2.557889775413375, 6.308801853496639, 1.814445686584846, 1.814445686584846,
    2.557889775413375, 6.308801853496639, 2.557889775413375, 6.308801853496639, 1.814445686584846, 1.814445686584846,
    2.557889775413375, 1.814445686584846, 1.814445686584846,
    0.907222843292423, 0.907222843292423, 0.907222843292423, 0.907222843292423, 0.907222843292423, 1.06814150219, 1.06814150219,
    0.907222843292423, 0.907222843292423, 0.907222843292423, 0.907222843292423, 0.907222843292423, 1.06814150219, 1.06814150219
  ]

  # No gamepad commands for mimic task
  commands: {}

  # ---------------------------------------------------------------------------
  # actions: post-processing of raw network output
  # [SOURCE] isaaclab/.../joint_actions.py: target = raw * scale + offset
  #          where offset = default_joint_pos (use_default_offset=True)
  # [SOURCE] processor.h: process_order [scale, offset] → x = x*scale + offset
  # All values from ONNX metadata (training order)
  # ---------------------------------------------------------------------------
  actions:
    JointPositionAction:
      process_order: [scale, offset]
      # [SOURCE] ONNX metadata: action_scale = 0.25 * effort / stiffness
      scale: [
        0.5475464629911068, 0.35066146637882434, 0.5475464629911068, 0.35066146637882434, 0.43857731392336724, 0.43857731392336724,
        0.5475464629911068, 0.35066146637882434, 0.5475464629911068, 0.35066146637882434, 0.43857731392336724, 0.43857731392336724,
        0.5475464629911068, 0.43857731392336724, 0.43857731392336724,
        0.43857731392336724, 0.43857731392336724, 0.43857731392336724, 0.43857731392336724, 0.43857731392336724, 0.07450087032950714, 0.07450087032950714,
        0.43857731392336724, 0.43857731392336724, 0.43857731392336724, 0.43857731392336724, 0.43857731392336724, 0.07450087032950714, 0.07450087032950714
      ]
      # [SOURCE] ONNX metadata: default_joint_pos (= action offset)
      offset: [
        -0.312, 0.0, 0.0, 0.669, -0.363, 0.0,
        -0.312, 0.0, 0.0, 0.669, -0.363, 0.0,
        0.0, 0.0, 0.0,
        0.2, 0.2, 0.0, 0.6, 0.0, 0.0, 0.0,
        0.2, -0.2, 0.0, 0.6, 0.0, 0.0, 0.0
      ]

  # ---------------------------------------------------------------------------
  # observations: assembled by PolicySlot::assembleObsFrame()
  # [SOURCE] ONNX metadata style:
  #   mimic(joint_pos+joint_vel+motion_anchor_ori_b)=64, base_ang_vel(3),
  #   joint_pos(29), joint_vel(29), actions(29) => Total 154
  #
  # NOTE: G1FlatWoStateEstimationEnvCfg removes:
  #   - motion_anchor_pos_b (set to None in flat_env_cfg.py)
  #   - base_lin_vel        (set to None in flat_env_cfg.py)
  # ---------------------------------------------------------------------------
  observations:
    stack:
      length: 1
      order: newest_first
    terms:
      mimic:
        params:
          source: local
          dim: 64
          terms: [joint_pos, joint_vel, motion_anchor_ori_b]
          local:
            file: src/legged_rl_deploy/policies/g1/mimic/LAFAN1_Retargeting/dance1_subject1/policy.onnx
            fps: 50
            hardware_order: false

      base_ang_vel_B:
      joint_pos:
        process_order: [offset]
        # Negated default_joint_pos (training order)
        offset: [
          0.312, 0.0, 0.0, -0.669, 0.363, 0.0,
          0.312, 0.0, 0.0, -0.669, 0.363, 0.0,
          0.0, 0.0, 0.0,
          -0.2, -0.2, 0.0, -0.6, 0.0, 0.0, 0.0,
          -0.2, 0.2, 0.0, -0.6, 0.0, 0.0, 0.0
        ]
      joint_vel:
      last_action:
